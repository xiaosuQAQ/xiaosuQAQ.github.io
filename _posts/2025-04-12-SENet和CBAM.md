---
title: "【论文阅读】SENet和CBAM浅读（简介+代码）"
author: Su Xiaofei
tags: 论文笔记
date: 2025-04-12
---
最近阅读和自己研究方向比较相近的几篇论文时，其中均使用了SENet和CBAM中的模块，分别是Momenta与牛津大学的《Squeeze-and-Excitation Networks》和韩国科学技术院的《CBAM: Convolutional Block Attention Module》，这两篇工作的思路都比较清晰直观，并且后者是对前者的改进。这两项工作的核心都是一个“即插即用”的模块，因此笔者对两篇工作进行简单地总结和分析，尽可能在原论文的基础上加入自己的理解。

## SENet

CNN中的卷积块提取特征时，融合了**空间**和**通道**中的信息，并且是一种“局部感受野”。这篇工作中，作者更加关注不同通道之间的关系，因此设计了全新的网络块——Sequeeze-and-Excitation Block（压缩-激励块）：将每个通道的信息压缩为一个数字，多个通道压缩后的数字输入全连接神经网络来显式建模通道之间的依赖关系，网络的输出作为激励与原始对应的通道相乘，从而激励网络关注更加重要的通道。这个SE块的特点主要有：

- 显式建模通道的依赖关系：将每个通道压缩、计算为一个数值，其数值直接反映该通道的重要程度；
- 自适应校准通道响应：全连接神经网络中的参数可学习，因此通道响应可以不断更新；

作者在ILSVRC上进行实验，取得了当年的SOTA，并且以很小的额外计算成本带来了显著的性能提升。
